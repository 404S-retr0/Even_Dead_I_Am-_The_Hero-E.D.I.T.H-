{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "friday_lang_detect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMANvhTcG0oOeT1I+xhuGe6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/404S-retr0/Even_Dead_I_Am-_The_Hero-E.D.I.T.H-/blob/main/friday_lang_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIkcl-LdPY-T"
      },
      "source": [
        "import string\r\n",
        "import re\r\n",
        "import codecs\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn import feature_extraction\r\n",
        "from sklearn import linear_model \r\n",
        "from sklearn import pipeline \r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "!wget https://raw.githubusercontent.com/404S-retr0/Even_Dead_I_Am-_The_Hero-E.D.I.T.H-/main/english_us_wordlist_top_100k.txt\r\n",
        "!wget https://raw.githubusercontent.com/404S-retr0/Even_Dead_I_Am-_The_Hero-E.D.I.T.H-/main/czech_wordlist_top_100k_2016_02_11.txt\r\n",
        "!wget https://raw.githubusercontent.com/404S-retr0/Even_Dead_I_Am-_The_Hero-E.D.I.T.H-/main/croatian_wordlist_top_100k.txt\r\n",
        "!wget https://raw.githubusercontent.com/404S-retr0/Even_Dead_I_Am-_The_Hero-E.D.I.T.H-/main/dutch_wordlist_top_100k_2012_05.txt\r\n",
        "!wget https://raw.githubusercontent.com/404S-retr0/Even_Dead_I_Am-_The_Hero-E.D.I.T.H-/main/danish_wordlist_top_100k_2011_12.txt\r\n",
        "eng_df = pd.read_csv(\"english_us_wordlist_top_100k.txt\",\"utf-8\",header=None,names=[\"English\"]) \r\n",
        "eng_df\r\n",
        "cro_df = pd.read_csv(\"croatian_wordlist_top_100k.txt\",\"utf-8\",header=None,names=[\"Croatian\"]) \r\n",
        "cro_df\r\n",
        "cze_df = pd.read_csv(\"czech_wordlist_top_100k_2016_02_11.txt\",\"utf-8\",header=None,names=[\"Czech\"]) \r\n",
        "cze_df\r\n",
        "dan_df = pd.read_csv(\"danish_wordlist_top_100k_2011_12.txt\",\"utf-8\",header=None,names=[\"Danish\"]) \r\n",
        "dan_df\r\n",
        "dut_df = pd.read_csv(\"dutch_wordlist_top_100k_2012_05.txt\",\"utf-8\",header=None,names=[\"Dutch\"]) \r\n",
        "dut_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zB0RcAZd0Qw",
        "outputId": "0da294ba-9c3f-46d9-ab28-29846ae099e4"
      },
      "source": [
        "for char in string.punctuation:\r\n",
        "  print(char,end=\" \")\r\n",
        "translate_table = dict ((ord(char),None) for char in string.punctuation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~ "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r7UoaJYd24T"
      },
      "source": [
        "data_eng = []\r\n",
        "lang_eng = []\r\n",
        "for i,line in eng_df.iterrows():\r\n",
        "  line = line['English']\r\n",
        "  if len(line) !=0:\r\n",
        "    line = line.lower()\r\n",
        "    line = re.sub(r\"\\d+\",\"\",line)\r\n",
        "    line = line.translate(translate_table)\r\n",
        "    data_eng.append(line)\r\n",
        "    lang_eng.append(\"English\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNoutTfZnTCN"
      },
      "source": [
        "data_cro = []\r\n",
        "lang_cro = []\r\n",
        "for i,line in cro_df.iterrows():\r\n",
        "  line = line['Croatian']\r\n",
        "  if len(line) !=0:\r\n",
        "    line = line.lower()\r\n",
        "    line = re.sub(r\"\\d+\",\"\",line)\r\n",
        "    line = line.translate(translate_table)\r\n",
        "    data_cro.append(line)\r\n",
        "    lang_cro.append(\"Croatian\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8sZmZHQnUAs"
      },
      "source": [
        "data_cze = []\r\n",
        "lang_cze = []\r\n",
        "for i,line in cze_df.iterrows():\r\n",
        "  line = line['Czech']\r\n",
        "  if len(line) !=0:\r\n",
        "    line = line.lower()\r\n",
        "    line = re.sub(r\"\\d+\",\"\",line)\r\n",
        "    line = line.translate(translate_table)\r\n",
        "    data_cze.append(line)\r\n",
        "    lang_cze.append(\"Czech\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh15rvcHnVKP"
      },
      "source": [
        "data_dan = []\r\n",
        "lang_dan = []\r\n",
        "for i,line in dan_df.iterrows():\r\n",
        "  line = line['Danish']\r\n",
        "  if len(line) !=0:\r\n",
        "    line = line.lower()\r\n",
        "    line = re.sub(r\"\\d+\",\"\",line)\r\n",
        "    line = line.translate(translate_table)\r\n",
        "    data_dan.append(line)\r\n",
        "    lang_dan.append(\"Danish\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq8LAh7knWN4"
      },
      "source": [
        "data_dut = []\r\n",
        "lang_dut = []\r\n",
        "for i,line in dut_df.iterrows():\r\n",
        "  line = line['Dutch']\r\n",
        "  if len(line) !=0:\r\n",
        "    line = line.lower()\r\n",
        "    line = re.sub(r\"\\d+\",\"\",line)\r\n",
        "    line = line.translate(translate_table)\r\n",
        "    data_dut.append(line)\r\n",
        "    lang_dut.append(\"Dutch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTw6q5CcgFQi"
      },
      "source": [
        "df=pd.DataFrame({\"Text\":data_eng+data_cro+data_cze+data_dan+data_dut,\r\n",
        "                 \"Language\":lang_eng+lang_cro+lang_cze+lang_dan+lang_dut})\r\n",
        "print(df.shape)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUSqXvb8po7T"
      },
      "source": [
        "x,y=df.iloc[:,0],df.iloc[:,1]\r\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(x_test.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cvLtC4RrKQB"
      },
      "source": [
        "vectorizer = feature_extraction.text.TfidfVectorizer(ngram_range=(1,2),analyzer='char')\r\n",
        "pipe_lr_r13 = pipeline.Pipeline([\r\n",
        "                                 ('vectorizer',vectorizer),\r\n",
        "                                 ('clf',linear_model.LogisticRegression())\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jNcvjk9s8po"
      },
      "source": [
        "pipe_lr_r13.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZvS8p93t9RD"
      },
      "source": [
        "y_predicted = pipe_lr_r13.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK0k7R-VuLnM"
      },
      "source": [
        "acc = (metrics.accuracy_score(y_test,y_predicted))*100\r\n",
        "print(acc,'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekydna0VvGu1"
      },
      "source": [
        "matrix = metrics.confusion_matrix(y_test,y_predicted)\r\n",
        "print('confusion matrix : \\n',matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsySunDHyacy"
      },
      "source": [
        "import pickle\r\n",
        "lrFile = open('LRModel.pckl','wb')\r\n",
        "pickle.dump(pipe_lr_r13,lrFile)\r\n",
        "lrFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlX1_PI21LrL"
      },
      "source": [
        "def lang_detect(text):\r\n",
        "  import numpy as np\r\n",
        "  import string\r\n",
        "  import re\r\n",
        "  import pickle\r\n",
        "  translate_table = dict ((ord(char),None) for char in string.punctuation)\r\n",
        "\r\n",
        "  global lrLangDetectModel\r\n",
        "  lrLangDetectFile = open('LRModel.pckl','rb')\r\n",
        "  lrLangDetectModel = pickle.load(lrLangDetectFile)\r\n",
        "  lrLangDetectFile.close();\r\n",
        "\r\n",
        "  text = \" \".join(text.split())\r\n",
        "  text = text.lower()\r\n",
        "  text = re.sub(r\"\\d\",\"\",text)\r\n",
        "  text = text.translate(translate_table)\r\n",
        "  pred = lrLangDetectModel.predict([text])\r\n",
        "  prob = lrLangDetectModel.predict_proba([text])\r\n",
        "  return pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZCd_i9p3BER"
      },
      "source": [
        "lang_detect(\"hello i just built my own language detection model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B21uFZip4RiW"
      },
      "source": [
        "lang_detect(\"vi\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}